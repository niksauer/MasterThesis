%!TEX root = ../main.tex

\addtocontents{toc}{\protect\newpage}

\chapter{Design \& Implementation}
\label{chp:architecture}

\section{Modeling as an Edge Cloud Computing Problem}
\label{sec:modeling-as-edge-cloud-problem}

Driven by applications with strict time-bound requirements such as the \ac*{IoT}, artificial intelligence or stream data analytics, a new computing model known as edge computing has emerged in recent years that pushes computations closer to the devices (\textit{edge}) where data is being generated \cite[p.~373]{xiong2018extend} \cite[p.~118]{alam2018orchestration}. This model does not only have the potential to improve application latency and thus, user-experience, but may also strengthen security and minimize bandwidth consumption by not having to transfer all data to centralized infrastructure (\textit{cloud})~\footnote{This centralized infrastructure may either follow an on-premise, off-premise or hybrid approach.} \cite[p.~295]{hoque2017towards}. Edge computing works complementary to the cloud, placing services at the most efficient and logical place between the producers and consumers of data \cite[p.~122]{alam2018orchestration}.

Applied to the problem at hand, one can easily see how a system supporting the data collection survey outlined in \autoref{sec:data-collection-survey} resembles that of a large distributed \acs*{IoT} application which leverages edge computing. Multiple geographically dispersed measurement devices gather meter data, analyze it for relevance (\textit{edge computing}), and then transfer the interesting measurements to a centralized data store for further in-depth processing (\textit{cloud computing}~\footnote{In this context, cloud computing does not necessarily imply the elasticity and self-service characteristics typically referred to (comp. \gls{cloud computing} in glossary).}). Therefore, the following sections will discuss the proposed solution's architecture in the context of edge and cloud realms, respectively.


\section{Component Design}
\label{sec:component-design}

Striving for a component-based design represents one of the most important practices in software engineering because it facilitates developers in maintaining a complex system by decomposing it into parts that are easier to conceive, understand and program (comp.~\nameref{sec:monolith-problem} on \autopageref{sec:monolith-problem}). At the same time, the process of dismantling a system should not happen arbitrarily but rather attempt to take the application's domain structure into account to reduce the likelihood of having to remedy large parts afterwards (comp.~\nameref{sec:microservice-decomposition} on \autopageref{sec:microservice-decomposition}).  Accordingly, \autoref{fig:component-design} presents a microservice-based approach (see~\autoref{sec:microservice-definition}) to modeling the system in question. It also gives a first indication as to how the components, i.e. microservices, will interact to achieve the desired behavior.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=\textwidth]{resources/04_architecture/component-design}
  \caption{High-level component design}
  \label{fig:component-design}
\end{figure}

\FloatBarrier


\subsection{Edge}
\label{sec:component-design-edge}

The edge of this system is composed by the set of measurement devices that are to be installed across the various participating households. Each measurement device will be fitted with the following set of microservices:

\begin{description}[format={\storedescriptionlabel}]
  \item[Data Aggregator\label{itm:data-aggregator}]
  \hfill \\
  The \ref{itm:data-aggregator} periodically (every 15 minutes) makes measurements for each of the electricity or generation meters connected to this device. Each connection is established on the basis of a dedicated physical measurement probe. Measurements will only be taken if the participant associated with this measurement device has granted his consent. As soon as the participant revokes his consent, measurements will stop indefinitely (comp.~\autoref{sec:survey-consent}). For each measurement made, the \ref{itm:data-aggregator} will extract the set of data points that are of interest to the survey and store those, if not empty, as a new single entry in a database along with the measurement date and identifier of the meter from which it originated. The interaction model with the database can be classified as append-only.

  \textbf{Realizes:} \ref{itm:survey-task-read-meters} on \autopageref{itm:survey-task-read-meters}

  \item[Data Transmitter\label{itm:data-transmitter}]
  \hfill \\
  The \ref{itm:data-transmitter} periodically (every 60 minutes, at minimum) transfers all of the measurements stored in the \ref{itm:data-aggregator}'s database to the cloud. Transfers are skipped if the participant associated with this measurement device has revoked or not yet granted his consent. Upon successful transfer, measurements will be deleted to avoid duplicate uploads in the future. Although this sharing of databases violates the database-per-service pattern (comp.~\autoref{sec:database-per-service-pattern}), it is still preferred due to the setup's simplicity. Otherwise, the \ref{itm:data-aggregator} would have to offer a network interface to retrieve and delete or modify measurements. This overhead is not warranted given the fact that the \ref{itm:data-aggregator} exclusively interacts with the database in an append-only mode.

  \textbf{Realizes:} \ref{itm:survey-task-transmit-measurements} on \autopageref{itm:survey-task-transmit-measurements}

  \item[Device Frontend\label{itm:device-frontend}]
  \hfill \\
  The \ref{itm:device-frontend} provides the participant associated with this device with a web-based user interface for granting and revoking his consent, viewing his registration details, as well as the measurements that have been made in and transferred from his household. Additionally, it will list the measurement devices which are in possession of that household and states to which meters and thus, \acsp{PVS}, each device is connected to. All of these details and actions are retrieved from and performed through the cloud. It shall be noted that a (desired) consequence of locating this component on the edge, rather than in the cloud, is that participants will no longer have access to this interface once they return their devices to the research group.

  \textbf{Realizes:} \ref{itm:fr-grant-consent}, \ref{itm:fr-revoke-consent}, \ref{itm:fr-revoke-consent-anonymize}, \ref{itm:fr-view-registration-details}, \ref{itm:fr-view-measurements}
\end{description}


\subsection{Cloud}
\label{sec:component-design-cloud}

The cloud of this system is composed by the following set of microservices:

\begin{description}[format={\storedescriptionlabel}]
  \item[Data \acs*{API}\label{itm:data-api}]
  \hfill \\
  The \ref{itm:data-api} acts as the single source of truth for each participant's registration details, consent, measurement devices and the measurements themselves. It offers a network interface to retrieve and modify these details, grant and revoke consent, and most importantly, add and retrieve measurements to and from a central data store that is accessible to the research group. Further, it takes care of anonymizing a participant's registration details upon revocation of his consent (see~\autoref{sec:survey-anonymization}) and tracks a measurement device's version and last date of activity. It may be argued that this component has a monolithic character due to the breadth of methods offered. Yet, the number of methods is not crucial to this judgement, but rather the degree to which they are related (comp.~\autoref{sec:microservice-definition} and \autoref{sec:microservice-decomposition}).

  \textbf{Enables:} \ref{itm:fr-grant-consent}, \ref{itm:fr-revoke-consent}, \ref{itm:fr-revoke-consent-anonymize}, \ref{itm:fr-view-registration-details}, \ref{itm:fr-view-measurements}, \ref{itm:fr-add-participant}, \ref{itm:fr-modify-registration-details}, \ref{itm:fr-view-consent}, \ref{itm:fr-view-health-status}

  \item[Registration Frontend\label{itm:registration-frontend}]
  \hfill \\
  The \ref{itm:registration-frontend} will allow researchers to add new participants, modify their registration details and check whether the consent of a participant has been granted or revoked. All of these details and actions are retrieved from and performed through the \ref{itm:data-api}.

  \textbf{Realizes:} \ref{itm:fr-add-participant}, \ref{itm:fr-modify-registration-details}, \ref{itm:fr-view-consent}

  \item[Status Frontend\label{itm:status-frontend}]
  \hfill \\
  The \ref{itm:status-frontend} provides administrators with a web-based user interface for viewing the health status of each measurement device. Specifically, it will list details such as the device's version, date of the last measurement and moment of activity. For convenience, it will also state to which household and participant a device belongs and whether the participant has granted or revoked his consent. All of these details are retrieved from the \ref{itm:data-api}.

  \textbf{Realizes:} \ref{itm:fr-view-health-status}
\end{description}


\section{Component Specification}
\label{sec:component-specification}

Having given a high-level overview of the components comprising the system, this section will formalize core aspects of the system's two most important microservices.

\subsection{\ref*{itm:data-api}}
\label{sec:component-specification-data-api}

\subsubsection{Data Model}
\label{sec:data-api-data-model}

Given the possibility that one human may wish to act as the contact person of two households which participate in the data collection survey (e.g. his own household and that of his parents), this component will model all data around a logical \texttt{Household} entity rather than that of a \texttt{User}. However, the contact details provided as part of the registration (see~\autoref{sec:survey-registration}) still indeed semantically belong to an individual user, i.e. a participant. These considerations lead to the initial entity-relationship model given in \autoref{fig:data-api-erm-user-household}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-1}
  \caption{Modeling of participants and households}
  \label{fig:data-api-erm-user-household}
\end{figure}

\FloatBarrier

Next, the answers to the location and metadata subjects of the registration form may be modeled as entities of the same names as shown in \autoref{fig:data-api-erm-household-metadata-address}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-2}
  \caption{Modeling of a household's metadata and address}
  \label{fig:data-api-erm-household-metadata-address}
\end{figure}

\FloatBarrier

Here, the decision to model the relationship as foreign keys with a unique constraint on the \texttt{Metadata} and \texttt{Address} entities shall be noted. This will lead to a \texttt{0..1} cardinality, meaning that this data does not necessarily have to be supplied for an individual household, even if its presence will be enforced on the application layer. The same result may be achieved through nullable foreign keys on the \texttt{Household} entity, although that approach would necessitate a primary key on the \texttt{Metadata} and \texttt{Address} entities which makes less sense conceptually since these details shall not exist on their own.

\newpage

Before the remaining registration details are modeled, two types of constants shall be introduced with \autoref{tab:meter-type-model-number-constants}. These constants will be used to differentiate electricity and generation meters, as well as to specify the model number of a meter itself. The latter is needed because the steps to take measurements from a meter will likely vary across models.

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|l|X|}
		\hline
		\textbf{Constant} & \textbf{Values} \\
	    \hline
	    \texttt{MeterType} & \texttt{ELECTRICITY}, \texttt{PV-GENERATION} \\
		\texttt{MeterModelNumber} & \texttt{MT681}, \texttt{MT175}, \texttt{EHZ}, \texttt{DD3}, \texttt{EASY} \\
	    	\hline
	\end{tabularx}
  	\caption{Meter type and model number constants}
  	\label{tab:meter-type-model-number-constants}
\end{table}

\FloatBarrier

Based on these constants, \autoref{fig:data-api-erm-household-meter-device-pv} models the relationship between a household's meters and \acsp{PVS}. It also associates each meter with a measurement device to indicate how these objects will be physically connected to each other later. As mentioned in the component design, this \texttt{MeasurementDevice} entity will need to track the device's version and date of last activity. Recalling the fact that microservices are deployed independently (comp.~\autoref{sec:microservice-definition}), the device's version will need to be split across multiple attributes, each tracking a different component running on the edge.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-3}
  \caption{Modeling of a household's meters, \acsp{PVS} and measurement devices}
  \label{fig:data-api-erm-household-meter-device-pv}
\end{figure}

\FloatBarrier

Now, only runtime-generated data is missing. Beginning with a participant's consent, \autoref{fig:data-api-erm-household-consent} details how the participation status of a household may be modeled. Again, this consent is associated with the \texttt{Household} entity rather than the \texttt{User} entity because one household may wish to stop sharing data earlier than the other.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-4}
  \caption{Modeling of a participant's consent}
  \label{fig:data-api-erm-household-consent}
\end{figure}

\FloatBarrier

Finally, the measurements taken from a particular meter are modeled in \autoref{fig:data-api-erm-meter-measurement}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-5}
  \caption{Modeling of a meter's measurements}
  \label{fig:data-api-erm-meter-measurement}
\end{figure}

\FloatBarrier

Of special note is the \acs{JSON} \texttt{data} attribute on the \texttt{Measurement} entity which will contain the actual data points that have been observed for a meter at a given point in time. In turn, this means that measurements will be stored in a denormalized manner. The shape and amount of data will vary across measurements. Several factors contribute to this modeling decision:

\begin{itemize}
  \item electricity and generation meters inherently produce different data
  \item different meter models may expose different data
  \item the data points of interest may vary across households and regions
\end{itemize}

As a result, the responsibility to ensure a consistent representation of measurement data is pushed to the application layer.


\paragraph{Anonymization Considerations}
In light of the data protection requirements formulated in \autoref{sec:survey-anonymization}, the data model shall be briefly verified for compatibility with the anonymization strategy presented therein.

\ref{itm:anonymization-step-remove-contact} is supported through the nullable foreign \texttt{User} entity key modeled on the \texttt{Household} entity which allows households to exist without participants and thus, without any contact details (comp.~\autoref{fig:data-api-erm-user-household}). On the other hand, \ref{itm:anonymization-step-anonymize-pvs} can be easily realized by modifying the attributes of a particular \acs{PVS} instance. However, because the \texttt{PhotovoltaicSystem} entity tracks the installation date as a \texttt{DATETIME}, this attribute will have to be normalized by setting the date to, for example, the first day of the year, rather than removing the date entirely and only keeping the year (comp.~\autoref{fig:data-api-erm-household-meter-device-pv}).

Lastly, even though \ref{itm:anonymization-step-anonymize-pvs} could be implemented based on the current data model, the following change should be made to further simplify the component's realization. It may be argued that because the process of generating a random location within a larger area is a geospatial operation, i.e. an algorithm which deals with geographic coordinate inputs \cite{de2007geospatial}, the component performing such an operation should also maintain geographic coordinates for the models on which it is operating. Currently, however, the \texttt{Household} entity is only associated with an \texttt{Address} entity that resembles a postal address. Therefore, an additional \texttt{Location} entity has been introduced in \autoref{fig:data-api-erm-household-location}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-6}
  \caption{Modeling of a household's location}
  \label{fig:data-api-erm-household-location}
\end{figure}

This location should be created simultaneously with the household's address but will then eventually outlive it once the anonymization has taken place. To create the initial location, the geographic coordinates which, in this case, are modeled as the latitude and longitude in the \ac{GPS}, may be retrieved based on the household's address (\textit{geocoding}).


\subsubsection{Service Interface}
\label{sec:data-api-service-interface}

While the microservice pattern does not dictate any specific kind of network interface for exposing a service's methods (comp.~\autoref{sec:microservice-definition}), \acs{REST} \acsp{API} have become ubiquitous and represent the de-facto industry standard approach \footnote{A full discussion on the principles of \acs{REST} is given in the \autoref{app:theoretical-framework} on \autopageref{sec:rest}.} \cite[p.~3]{rapidapi2020}. For that reason, \autoref{tab:data-api-endpoints} breaks down the service's functionalities into a set of \acs{HTTP}-based \acs{REST} endpoints and maps each endpoint to the requirements satisfied thereof. A complete documentation based on the OpenAPI specification format is available as part of this thesis' hand-in~\footnote{\url{https://swagger.io/specification}}.

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|c|c|l|X|}
		\hline
		\textbf{\#} & \textbf{Method} & \textbf{Path} & \textbf{Requirements} \\
	    \hline
	    \labeltext[Endpoint~1]{1}{itm:data-endpoint-1} & \texttt{GET} & \texttt{/account} & \ref{itm:fr-view-registration-details} \\
	    \labeltext[Endpoint~2]{2}{itm:data-endpoint-2} & \texttt{GET} & \texttt{/household} & \ref{itm:fr-view-registration-details} \\
	    	\labeltext[Endpoint~3]{3}{itm:data-endpoint-3} & \texttt{POST} & \texttt{/household/consent} & \ref{itm:fr-grant-consent} \\
	    	\labeltext[Endpoint~4]{4}{itm:data-endpoint-4} & \texttt{DELETE} & \texttt{/household/consent} & \ref{itm:fr-revoke-consent}, \ref{itm:fr-revoke-consent-anonymize} \\
	    \labeltext[Endpoint~5]{5}{itm:data-endpoint-5} & \texttt{GET} & \texttt{/household/measurement\_device} & \\
	    	\labeltext[Endpoint~6]{6}{itm:data-endpoint-6} & \texttt{GET} & \texttt{/household/meter} & \ref{itm:fr-view-registration-details} \\
	    \labeltext[Endpoint~7]{7}{itm:data-endpoint-7} & \texttt{GET} & \texttt{/household/meter/:uuid/measurement} & \ref{itm:fr-view-measurements} \\
	    \labeltext[Endpoint~8]{8}{itm:data-endpoint-8} & \texttt{POST} & \texttt{/household/meter/measurement} & \ref{itm:survey-task-read-meters} \\
	    	\labeltext[Endpoint~9]{9}{itm:data-endpoint-9} & \texttt{GET} & \texttt{/household/pv\_system} & \ref{itm:fr-view-registration-details} \\
	    \labeltext[Endpoint~10]{10}{itm:data-endpoint-10} &	\texttt{GET} & \texttt{/management/household} & \ref{itm:fr-view-consent}, \ref{itm:fr-view-health-status} \\
	    	\hline
	\end{tabularx}
  	\caption{\ref*{itm:data-api} endpoints mapped to requirements}
  	\label{tab:data-api-endpoints}
\end{table}

\FloatBarrier


\subsubsection{Access Control}
\label{sec:data-api-access-control}

Since this microservice will be publicly exposed for consumption by the edge clients, as well as the \ref{itm:registration-frontend} and \ref{itm:status-frontend} (comp.~\autoref{fig:component-design}), appropriate measures must be put into place to protect the component from unauthorized access. In terms of access control, authentication and authorization are key to these concerns.

\begin{description}

  \item[Authentication\label{itm:data-api-authentication}]
  \hfill \\
  The component will need to implement some form of authentication in order to verify the identify of the user, i.e. the participant, researcher or administrator, for whom access to a service is requested. Verification typically happens on the basis of something that the requesting party should know (e.g. password), posses (e.g. access card) or incarnate (e.g. biometrics).

  \paragraph{Edge clients}
  Edge clients will need to posses a digital certificate and present it with every request. Such certificates are generally used to prove the ownership of a public key by carrying an appropriate signature. Moreover, they can be extended with additional metadata that is then also attested by the signature \cite[p.~37]{hummen2013towards}. Based on these cryptographic guarantees, the component will authenticate requests by matching the metadata encoded in a certificate against the stored participant registration details. In particular, it will expect each certificate to encode an email address that belongs to a participant. This lookup scheme is supported by the fact that the \texttt{email} attribute in the \texttt{User} entity has been modeled with a unique constraint (comp.~\autoref{fig:data-api-erm-user-household}), ensuring that any given email address can, at most, identify one participant. Of course, the signature of the presented certificate must also be checked to ensure that it comes from a public key which is exclusively owned by this component or some trusted party associated with the data collection survey. Otherwise, requesting parties could self-attest their identity.

  The main benefit of this authentication method is the ability to preload edge devices with certificates~\footnote{The patent presented in \cite{etchegoyen2013device} describes a method for binding digital certificates to one or more devices. In case of a breach, access for individual devices, rather than users, can be revoked.}~\footnote{\citeauthor{ammar2018internet} warn that embedding a key in a device can represent a security risk, if not regularly rotated, since, eventually, all cryptographic algorithms will be broken \cite[p.~23]{ammar2018internet}.}. In theory, this allows a measurement device to transmit data as soon as it is connected to a meter.

  \paragraph{\ref*{itm:registration-frontend} and \ref*{itm:status-frontend}}
  These frontends will need to know a shared secret and present it with every request. The secret will collectively identify the research or administrator group, meaning that individual researchers and administrators are not discerned. Such differentiation is not needed as per the requirements presented in \autoref{sec:functional-requirements}.

  \item[Authorization\label{itm:data-api-authorization}]
  \hfill \\
  Once users have been identified and authenticated, the component will need to determine whether they are authorized to use the requested service method. Therefore, \autoref{tab:data-api-endpoints-user-groups} details which user group shall be permitted to which of the service's endpoints. \autoref{tab:data-api-endpoints-permission-scopes} further specifies which set of permissions (\textit{scope}) a user must have to access a particular service endpoint.

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|l|X|}
		\hline
		\textbf{User Group} & \textbf{Endpoints} \\
	    \hline
	    Participants & \ref{itm:data-endpoint-1} -- \ref{itm:data-endpoint-9} \\
		Administrators & \ref{itm:data-endpoint-10} \\
	    	\hline
	\end{tabularx}
  	\caption{\ref*{itm:data-api} endpoints mapped to user groups}
  	\label{tab:data-api-endpoints-user-groups}
\end{table}

\FloatBarrier

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|l|X|}
		\hline
		\textbf{Scope} & \textbf{Endpoints} \\
	    \hline
	    \texttt{account} & \ref{itm:data-endpoint-1} \\
		\texttt{household} & \ref{itm:data-endpoint-2}, \ref{itm:data-endpoint-5}, \ref{itm:data-endpoint-6}, \ref{itm:data-endpoint-9} \\
		\texttt{consent} & \ref{itm:data-endpoint-3}, \ref{itm:data-endpoint-4} \\
		\texttt{measurement-read} & \ref{itm:data-endpoint-7} \\
		\texttt{measurement-write} & \ref{itm:data-endpoint-8} \\
	    	\hline
	\end{tabularx}
  	\caption{\ref*{itm:data-api} endpoints mapped to permission scopes}
  	\label{tab:data-api-endpoints-permission-scopes}
\end{table}

\FloatBarrier

	Scopes support the principle of least privilege. For instance, the \ref{itm:data-transmitter} only needs the \texttt{measurement-write} scope to perform its primary task of uploading measurements (in addition to the \texttt{consent} scope to check whether uploads may take place), whereas the \ref{itm:device-frontend} requires the \linebreak \texttt{measurement-read} scope to retrieve individual measurements for display. These scopes may be granted based on the user's group or other metadata which is encoded in a certificate~\cite[p.~1]{butt2004certificate}.
\FloatBarrier

\end{description}

With regard to shielding data of one participant from that of another, the service interface has already been designed from the perspective of the currently authenticated user (comp.~\ref{itm:data-endpoint-1} -- \ref{itm:data-endpoint-9} in \autoref{tab:data-api-endpoints}). Hence, no additional access control measures are needed.


\subsection{\ref*{itm:data-aggregator}}
\label{sec:component-specification-data-aggregator}

\subsubsection{Data Model}
\label{sec:data-aggregator-data-model}

In true microservice fashion, this component will only need to model a single entity which is precisely that of a measurement taken from a meter. Its attributes match those of the \texttt{Measurement} entity introduced in \autoref{fig:data-api-erm-meter-measurement}, except that the \texttt{meter} attribute cannot be modeled as a foreign key. This difference is shown in \autoref{fig:data-aggregator-erm}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.38\textwidth]{resources/04_architecture/data-aggregator-erm}
  \caption{Modeling of an edge client's measurements}
  \label{fig:data-aggregator-erm}
\end{figure}

Recalling the fact that the application layer is responsible for ensuring a consistent representation of measurement data, a short explanation shall be given as to how this will be achieved. Since the data collection survey is particularly interested in meters which utilize the \acf{SML} communication protocol to expose internal measurement data (see~\autoref{sec:survey-overview}), its representation of measured values (e.g. counter readings or specific amounts of energy) is decisive for this question. The \ac{SML} protocol uses the \ac{OBIS} to denote data items in metering equipment. Its codes have been standardized in \acs{IEC} 62056-6-1 \cite{iec2017obis}. For this survey, the \ac{OBIS} codes listed in \autoref{tab:relevant-obis-codes} are most relevant~\footnote{A description of common \acs{OBIS} codes is available at \url{https://promotic.eu/en/pmdoc/Subsystems/Comm/PmDrivers/IEC62056_OBIS.htm}}.

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|l|l|X|}
		\hline
		\textbf{Hex Code} & \textbf{Short Code} & \textbf{Description} \\
	    \hline
	    \texttt{0100010800ff} & \texttt{1.8.0} & Positive active energy total (in \si{\kilo\watt\hour}) \\
	    	\texttt{0100020800ff} & \texttt{2.8.0} & Negative active energy total (in \si{\kilo\watt\hour}) \\
	    \texttt{0100010700ff} & \texttt{1.7.0} & Positive active instantaneous power (in \si{\kilo\watt}) \\
	    \texttt{0100020700ff} & \texttt{2.7.0} & Negative active instantaneous power (in \si{\kilo\watt}) \\
	    	\texttt{0100100700ff} & \texttt{16.7.0} & Sum active instantaneous power (in \si{\kilo\watt}) \\
	    	\hline
	\end{tabularx}
  	\caption{Relevant \acs*{OBIS} codes in metering equipment}
  	\label{tab:relevant-obis-codes}
\end{table}

\FloatBarrier

Given these codes, the component will store the relevant measurement data as a \acs{JSON} array of objects that map each observed \acs{OBIS} code to the value observed for that code. However, because the \acs{OBIS} short code is not uniquely identifiable~\footnote{\ac{OBIS} short codes do not carry the physical medium and channel from which data was generated~\cite{iec2017obis}.}, the hexadecimal representation shall be used.


\subsubsection{Control Flow}
\label{sec:data-aggregator-control-flow}

Although the component's overall control flow has already been discussed in \autoref{sec:component-design-edge} on \autopageref{itm:data-aggregator}, one crucial aspect has not been mentioned so far -- namely, that the electricity and generation meters installed in a household may be factory locked. Such meters may not expose all of their internal measurement data. Therefore, it will be necessary to monitor the \acs{SML} stream for the expected \acs{OBIS} codes (see~\autoref{tab:relevant-obis-codes}), and attempt an unlock if the condition appears to persist over a longer period of time. This revised control flow is depicted in \autoref{fig:data-aggregator-control-flow}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=\textwidth]{resources/04_architecture/data-aggregator-flowchart}
  \caption{Control flow of the \ref*{itm:data-aggregator}}
  \label{fig:data-aggregator-control-flow}
\end{figure}

\FloatBarrier

Unlocking a meter involves entering a \acs{PIN} code. This code will, in the most cases, have to be obtained from the household's energy supplier. The actual \acs{PIN} input may then happen physically in advance to this survey or programmatically at runtime through the meter's optical interface (comp.~\autoref{sec:survey-overview}).


\section{Component Realization}
\label{sec:component-realization}


\subsection{Certificate-based Authentication}
\label{sec:certificate-based-authentication}

The certificate-based authentication scheme outlined in \autoref{sec:data-api-access-control} on \autopageref{itm:data-api-authentication} is already standardized as an extension to the \acs{TLS} protocol, known as \ac{mTLS}.

Whereas \acs{TLS} is traditionally used to ensure the secrecy and integrity of data exchanged in a \acs{TCP} connection, as well as to authenticate the server with which a client is communicating, \acs{mTLS} offers a way for clients to authenticate themselves to servers, if requested, without having to disclose a shared secret \cite[p.~1]{parsovs2013practical}. For that purpose, the \acs{TLS} handshake has been extended with an optional \texttt{CertificateRequest} message. This message includes a list of \acp*{DN} of \acp*{CA} that the server trusts, i.e. a list of parties from which certificates must originate. Based on this list, clients can select one or more certificates and respond to the server's authentication request with a \texttt{Certificate} message. These certificates must follow the X.509 standard as defined by the \acl*{ITU}. Finally, the client will have to prove access to the private key corresponding to the public key referenced in the certificate. This is done by calculating and signing a hash of all previous handshake messages which is then sent to the server for verification in a \texttt{CertificateVerify} message. It is exactly this randomness that prevents a signature and thus, the certificate, from being exploited in and being susceptible to phishing and replay attacks. Even if an attacker obtains the signature in a man-in-the-middle attack, he cannot impersonate the victim \cite[p.~2]{parsovs2013practical}.

\acs{mTLS} is suitable to this application context because the service interface of the \ref{itm:data-api} is based on \acs{HTTP} (comp.~\autoref{sec:data-api-service-interface}) which, in turn, leverages \acs{TCP}. To successfully use this technology, the system will have to:

\begin{itemize}
  \item establish its own \acs*{CA} or trust a third party
  \item issue X.509 certificates that encode the participant's email address and, optionally, the required scopes (comp.~\autoref{sec:data-api-access-control})
  \item embed a certificate in each measurement device
  \item verify the certificate presented with each request~\footnote{\citeauthor{parsovs2013practical} recommends using the \acs{TLS} session resumption feature to avoid an additional network round-trip and private key operation on repeated requests \cite[p.~3]{parsovs2013practical}.}
\end{itemize}

For these tasks, an extensive amount of infrastructure, tools and expertise can be reused \cite[p.~37]{hummen2013towards}.


\paragraph{\ref*{itm:device-frontend} Considerations}
It shall be noted that \acl*{JS} lacks \acsp{API} to comfortably interact with a browser's client certificate store. For instance, it is not possible to implement a logout functionality that clears the current session's certificate choice \cite[p.~8]{parsovs2013practical}. Such functionality, however, is required in client-side web applications, such as the \ref{itm:device-frontend}, which should be protected from unauthorized access. Moreover, using certificate-based authentication in such applications assumes that users have access to certificates. In this application context, however, certificates are only embedded in measurement devices. And since these measurement devices are headless (comp.~\autoref{sec:survey-overview}), participants will be required to use another, separate device to access the \ref{itm:device-frontend}. This problem can be solved by either:

\newpage

\begin{itemize}
  \item sharing the certificate with the participant, so that he can add it to each of the devices used to access the frontend
  \item funneling each of the frontend's requests through another component (\textit{proxy}) running on the measurement device
\end{itemize}

For the sake of user experience, as well as security concerns, the latter option should be preferred~\footnote{Participants would otherwise become responsible for configuring certificates in their browsers. This may represent a hurdle in itself. Further, no guarantees can be made about their browsers' security. In the worst case, certificates may leak and be used to impersonate a participant.}.


\subsection{Anonymization of Location}
\label{sec:anonymization-of-location-realization}

The task of anonymizing a household's location in compliance with \autoref{sec:survey-anonymization} can be split into two main steps:

\begin{enumerate}[label=(\Alph*)]
  \item \labeltext[Step~(A)]{calculate distance bounds $d_{\text{min}}$ and $d_{\text{max}}$ according to \autoref{eq:anonymize-location-min-max-distance}}{itm:location-anonymization-step-calculate-bounds}
  \item \labeltext[Step~(B)]{generate random location that has a distance ($d$) from the household's location which satisfies $d_{\text{min}} \leq d \leq d_{\text{max}}$}{itm:location-anonymization-step-generate-random-location}
\end{enumerate}

Beginning with \ref{itm:location-anonymization-step-calculate-bounds}, an algorithm will, for any given household, first need to lookup the population density per square kilometer ($\rho_N$). Of course, this density will greatly depend on the chosen granularity (e.g. state, province or region). For Europe, the \ac{NUTS} has gained acceptance. This geocode standard subdivides countries on three hierarchy levels, though each division happens in agreement with the respective member state, meaning that a level in one country may refer to a concept which is different from that in another. In Germany, the levels 1--3 refer to states, government regions and districts, respectively \cite[p.~6]{eurostat2020nuts}. For this application, \ac{NUTS} 3 will be used.

Now, in order to lookup the population density on this level, the actual \acs{NUTS} 3 code will have to be determined for the given household. Recalling the fact that each household is associated with a \ac{GPS} position (comp.~\autoref{fig:data-api-erm-household-location}), an algorithm may calculate this code by mapping the position onto a map that draws in the individual subdivisions. In geospatial analysis, this is done using a polygon that represents the geographic bounds of a particular area. A common data format for storing such polygons and other spatial features, i.e. points and lines, is known as a \textit{shapefile} \cite{de2007geospatial}. For Germany, the \acl*{BKG} maintains various such shapefiles for different kinds of subdivisions, including \acs{NUTS}~\footnote{\url{https://gdz.bkg.bund.de/index.php/default/digitale-geodaten.html}}. Once the code is known, a database, such as that provided by the Federal Statistical Office (German: \textit{Statistisches Bundesamt})~\footnote{\url{https://destatis.de/DE/Themen/Laender-Regionen/Regionales/Gemeindeverzeichnis/Administrativ/04-kreise.html}}, can be used to retrieve the population density.

Continuing with \ref{itm:location-anonymization-step-generate-random-location}, the problem of generating a random location ($p$) that has a distance ($d$) from the household's location ($p_0$) which satisfies $d_{\text{min}} \leq d \leq d_{\text{max}}$ may be understood as illustrated in \autoref{fig:random-location-bounds}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.55\textwidth]{resources/04_architecture/rejection-sampling}
  \caption{Random location bounds for anonymization}
  \label{fig:random-location-bounds}
\end{figure}

Here, the distance bounds $d_{\text{min}}$ and $d_{\text{max}}$ are used as the radii for circles drawn around a center $p_0$. Points generated within the green area should be accepted, whereas points in the red areas are either too close or too far away and thus, should be rejected. Again, this problem can be solved with two geographic polygons that represent the inner and outer circles. For the most precise result, each polygon would consist of 360 points. In order to then generate a random location $p$, an algorithm can take the square bounds ($x_{\text{min}}, x_{\text{max}}, y_{\text{min}}, y_{\text{max}}$) of the outer circle and generate two random coordinates ($x,y$). The resulting point is then checked against both circles as stated above. The process should be repeated until a valid point and thus, location, has been found. This technique is known as \textit{rejection sampling}.


\subsection{Meter Interaction}
\label{sec:meter-interaction}

\subsubsection{Optical Interface}
\label{sec:meter-interface}

So far, the probe used to take measurements from a meter, as well as to control its menu, has only been described vaguely. To understand its construction and way of working, the direct local data exchange standard in electricity metering must first be presented.

\acs{IEC} 62056-21 standardizes an optical interface and several protocol modes that permit both reading and programming of meters~\footnote{In addition to this galvanically isolated interface, \acs{IEC} 62056-21 also standardizes an electrical coupling method for use in more permanent setups, or when more than one meter needs to be read at one site \cite[p.~15]{iec2002d0}.} \cite[p.~15]{iec2002d0}. This optical interface is realized using an infrared receiver and transmitter which interpret and generate light signals according to predefined limiting values (\textit{optocoupler}). In other words, the receiver will, depending on the signal's radiation strength, interpret a light signal as an \texttt{ON}- (binary \texttt{0}) or \texttt{OFF}-condition (binary \texttt{1}), whereas the transmitter will, depending on the desired binary state, generate a light signal of appropriate radiation strength \cite[pp.~30--31]{iec2002d0}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.55\textwidth]{resources/04_architecture/meter-schematics}
  \caption[Optical interface of a meter]{Optical interface of a meter, consisting of an infrared receiver (1) and transmitter (2) \cite[p.~7]{nzr2011ehz}}
  \label{fig:meter-schematics}
\end{figure}

\FloatBarrier

Given this description, it is clear that the measurement probe will function analogously, meaning that it also consists of an infrared receiver and transmitter but has these aligned vice-versa to those in the meter. In \acs{IEC} 62056-21, such a component is known as a reading head~\footnote{To ensure broad compatibility of reading heads, the dimensions of the optical port, i.e. the diameter of and distance between the receiver and transmitter, have also been standardized as part of \acs{IEC} 62056-21 \cite[p.~25]{iec2002d0}.} \cite[p.~29]{iec2002d0}.

While in theory this setup would allow for an arbitrary data exchange, consumer-facing meters are, by default, configured to operate in protocol mode D which only permits data readout \cite[p.~7]{nzr2011ehz} \cite[p.~35]{iec2002d0}. The infrared receiver, in this mode, is only used to navigate a meter's menu, including entering a \acs{PIN} to enable a more detailed readout (see \autoref{sec:data-aggregator-control-flow}). This is likely the reason why a meter's optical port is colloquially referred to as the D0 interface, where 0 stands for the channel number used by electricity metering \cite[p.~119]{iec2002d0}.


\subsubsection{Data Readout}
\label{sec:meter-data-readout}

Once the measurement probe described above is connected to a measurement device (e.g. via USB), the \ref{itm:data-aggregator} will have access to a continuous stream of bits that represent parts of the \acs{SML} telegrams successively emitted by a meter. Naturally, these bits will have to be buffered until a complete telegram can be reconstructed. The exact format, as well as the different types of \acs{SML} messages available, are standardized in \acs{DIN} \acs{VDE} 0418-63-9 \cite{vde2018sml}. Therefore, this section will not go into further detail, even more so because this task will likely be delegated to a third-party library~\footnote{\url{https://github.com/spacemanspiff2007/SmlLib}}. However, it shall be noted that multiple different (sub-)versions of the \acs{SML} communication protocol exist. This must be taken into account by the \ref{itm:data-aggregator}.


\subsubsection{\acs*{PIN} Input}
\label{sec:meter-pin-input}

The process of entering a meter's \acs{PIN} has, unfortunately, not been standardized as rigorously. In fact, during the course of this project, it has been observed that the steps, i.e. the signal lengths and pauses required in-between, vary from model to model and sometimes, even for the same model. Further, some models protect the detailed data readout by hiding it behind an additional menu setting. Therefore, it is safe to say that this aspect of the system represents the greatest barrier to compatibility and inclusion of a household in the data collection survey.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.75\textwidth]{resources/04_architecture/meter-interface-class-diagram}
  \caption{Abstract meter interface to enable a more detailed data readout}
  \label{fig:meter-interface-class-diagram}
\end{figure}

\FloatBarrier

To hide this complexity and thus, streamline application code, the interaction (e.g.~\texttt{enable\_detailed\_readout()}) with a specific meter model (e.g.~\texttt{MT681}) shall happen on the basis of a generic \texttt{MeterInterface} class. This class may be subclassed to create specialized versions that encapsulate the timing details for each particular meter model (comp.~\autoref{fig:meter-interface-class-diagram}). At runtime, the factory pattern may then be used to obtain an appropriate instance.


\section{Deployment Model}
\label{sec:deployment-model}

In light of the lengthy discussion on the benefits of containerized applications in \autoref{sec:docker} and \autoref{sec:shift-to-container-workloads}, it should come as no surprise that this system will fully embrace containers as the deployment target and medium of choice. This choice is also a major enabler to the system's portability since containers are not bound to a specific hardware platform. They only need to be compatible with the host's kernel and \acs{CPU} architecture (comp.~\autoref{sec:os-hardware-virtualization-comparison}). On the other hand, to simplify the management of these containers, the system will rely on a container orchestration platform as was presented in \autoref{sec:container-orchestration-platform}.

\newpage

\subsection{Target Hardware}
\label{sec:deployment-target-hardware}

A brief overview of the currently targeted hardware and thus, \acs{CPU} architectures, shall be given in the following~\footnote{The Linux kernel versions have been disregarded because container runtimes, such as the one used by Docker, only requires version 3.10 which is an almost 9-year old release that reached its end of life in late 2017 \cite{dockerEngine} \cite{lkml2018eol}.}:

\begin{description}
  \item[Edge]
  \hfill \\
  Each measurement device shall be realized on the basis of a Raspberry Pi 4 Model B with \SI{4}{\giga\byte} of memory. This single-board computer is equipped with a 64-bit quad-core Cortex-A72 processor that is based on version 8 of the \acs{ARM} instruction set architecture (\texttt{armv8}) \cite{raspberrypi4} \cite{arm2020v8a}. In this price range, most devices run on \acs{ARM}. Therefore, this will be the primary target architecture going forward~\footnote{Usage of the \acs{ARM} architecture generally also leads to more power-efficient designs, which is a valuable trait considering that measurement devices will run on a household's own electricity~\cite[p.~8837]{morabito2017virtualization}.}.

  \item[Cloud]
  \hfill \\
  The set of services representing the cloud shall be deployed using the compute infrastructure provided by the university. The exact configuration matters less in this case because, here, resources are provisioned on the basis of \acsp{VM} which, on request, may be reconfigured for more memory or \acs{CPU} cores. More importantly, all \acsp{VM} will run on the 64-bit version of the x86 instruction set architecture (\texttt{x86-64}). This architecture has, traditionally, always been used for server workloads which is why it will be the primary target going forward~\footnote{Amazon Web Services has only recently launched \acs{ARM}-based versions of its compute instance families. According to a Bloomberg report, Microsoft is also designing its own chips for use in its \gls{cloud computing} offerings and consumer devices \cite{bloomberg2020microsoft}.}.
\end{description}

It shall be noted that the development of the components comprising this system will take place in an x86-based environment. Therefore, so-called multi-architecture builds will be necessary to enable local testing. Such functionality has recently been added to Docker \cite{docker2020multi}. Technically, this is achieved through emulation by a hypervisor~\footnote{While Docker ensures that a build is performed in the context of a specific \acs{CPU} architecture, it is up to the developer to ensure that libraries and application code are compatible with that particular architecture.}.


\subsection{Container Builds and Registry}
\label{sec:deployment-container-builds-and-registry}

As previously hinted at, this project will leverage Docker to build container images. Portability of build artifacts, again, is ensured by the fact that Docker builds \acs{OCI}-compliant images (comp.~\autoref{sec:docker}). Now, to use these images in an actual deployment, the build artifacts will have to be distributed to the execution hosts. In non air-gapped systems such as this one, a container image registry is typically used for this task. However, because the licensing model of this application has not yet been decided upon, a private registry, or rather repository, shall be used, i.e. one to which only a limited audience has access to. Finally, to make this process automatic and reproducible for any given revision of a component's code, a continuous delivery pipeline will be employed as is described in the \autoref{app:theoretical-framework} on \autopageref{sec:continuous-deployment}.


\subsection{Container Orchestrator}
\label{sec:deployment-container-orchestrator}

To manage and deploy the aforementioned containers, this project will rely on Kubernetes~\footnote{\url{https://kubernetes.io}}, a state-of-the-art container orchestration platform that exhibits and goes well beyond the minimum set of characteristics pressed for in \autoref{sec:container-orchestration-platform-capabilities}. Originally developed at Google, Kubernetes builds upon more than a decade and a half of experience running containerized production workloads at scale \cite[p.~50]{burns2016borg}. It is also the primary solution recommended and hosted by the \acl*{CNCF} \cite[p.~13]{pahl2017cloud}.


\paragraph{Resource Considerations}

Even though the currently targeted edge client hardware is powerful in comparison to its size, care should be taken in the choice of container orchestrator. Optimizing this choice for resource usage will allow less well-equipped hardware to be used in the future. Moreover, whereas an orchestrator running in the cloud typically attempts to maximize resource utilization, single-node edge orchestrators will not have to move and migrate containers as frequently and thus, can be built to use minimal resources \cite[p.~2]{goethals2019fledge}. For this purpose, lightweight distributions of Kubernetes have emerged which promise savings by modifying and reorganizing some of the core components \cite[pp.~65--66]{bohm2021profiling}. Based on the findings in \cite{bohm2021profiling} and \cite{goethals2019fledge}, this project will use the K3s distribution of Kubernetes to manage and deploy containers on the edge~\footnote{\url{https://k3s.io}}.


\section{Maintenance and Support Plan}
\label{sec:maintenance-and-support-plan}

A major objective of this thesis is the design of a maintenance and support plan through which the system can be effortlessly operated, upgraded and serviced over the course of the data collection survey (comp.~\autoref{sec:goals-and-scope}). This is especially important considering that measurement devices will be located in various geographic regions, making physical access to these devices impossible or impractical at the very least. More so, it cannot be expected that the participants of the survey will have enough technical knowledge to aid in support beyond rebooting a particular device. Therefore, this section will discuss three approaches relevant to this stage of the application lifecycle.


\subsection{Remote Updates}

While it is easy to see how the initial setup of a measurement device and deployment of the services running on it may happen on the basis of a custom system image, it is less clear how these components will be updated once the device has been installed in a household. For this, a high-level understanding of a deployment in Kubernetes is needed.

At the heart, Kubernetes works in a declarative manner, meaning that users describe a desired cluster state based on which control loops then watch the cluster and make or request changes that move the current state closer to this desired state (comp.~\acs{MAPE-K} cycle in \autoref{sec:orchestration-reference-architecture}) \cite{kubernetesControllers}. For instance, so-called replication controllers will monitor a service's replica count and attempt to create or destroy additional instances if the actual count does not match the user-provided specification. Now, given the fact that Kubernetes uses configuration files to formulate such a desired cluster state~\footnote{Kubernetes also allows for the possibility to use imperative commands for managing a cluster. However, because these commands effectively only alter the previous desired state, i.e. that specified through the series of commands executed prior, this method is not listed explicitly~\cite{kubernetesImperative}.}, a workflow can be designed that allows components to be updated remotely without requiring a participant's input. Of course, this workflow may also be used to update the cloud's components.

In this workflow, a \acs{VCS} repository will contain the complete set of configuration files needed to describe a particular revision of the system's deployment. Then, a so-called operator, i.e. an extension to Kubernetes, will continuously monitor the repository for changes and instruct the orchestrator to use the most recent revision as the cluster's desired state~\footnote{\url{https://fluxcd.io}}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=\textwidth]{resources/04_architecture/gitops-workflow}
  \caption{Workflow to achieve remote component updates}
  \label{fig:gitops-workflow}
\end{figure}

\FloatBarrier

This workflow inherently decouples the update process from the execution hardware, allowing individual devices to fail intermittently but then self-heal by applying the latest configuration revision. Decoupling these steps also helps in scaling the system since administrators will not have to interact with each individual measurement device in order to perform an update.

Two additional advantages of this approach shall be noted. Firstly, the workflow prepares for the possibility to practice \acl{CD} (see~\autoref{app:theoretical-framework} on \autopageref{sec:continuous-deployment}). This practice can be easily attained by extending the pipeline mentioned in \autoref{sec:deployment-container-builds-and-registry} to update the cluster configuration files whenever a new container image has been built. Secondly, by storing the cluster's configuration in a \acs{VCS} repository, users outside of the operations team can be empowered to do their own operations, lowering the bar for self-service systems~\footnote{The article in \cite{limoncelli2018gitops} goes into great detail on the benefits of this \acs{VCS}-driven workflow and culture, known as GitOps.} \cite[p.~38]{limoncelli2018gitops}.

\textbf{Realizes:} \ref{itm:fr-update-device}


\subsection{Remote Access}

For debugging purposes and other maintenance activities, it will be necessary to remotely connect to measurement devices via \acs{SSH}. However, because these devices will be situated on a network whose firewall only allows outbound connections, i.e. the household's \acs{LAN}, direct access (\textit{forward connection}) will not be possible. Besides, it is unlikely that the household will have a publicly reachable \acs{IP} address~\footnote{\acsp{ISP} use \acs{NAT} to route traffic from the internet to their customers who have been assigned private \acs{IP} addresses. The reason why customers have been given these addresses is due to the limited amount of public \acs{IP}v4 addresses. \acs{IP}v6 may change this situation with its 128-bit (versus 32-bit) address space.}. Such (static) public \acsp{IP} are usually reserved for commercial internet plans. Instead, a \textit{reverse connection} approach will be used as is shown in \autoref{fig:remote-ssh-tunnel}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.85\textwidth]{resources/04_architecture/reverse-ssh-tunnel}
  \caption{Reverse \acs*{SSH} tunnel to allow remote access}
  \label{fig:remote-ssh-tunnel}
\end{figure}

\FloatBarrier

Here, each measurement device will establish a long-lived \acs{TCP}/\acs{IP} connection (\textit{tunnel}) with one of the system's cloud servers which are situated on the public internet and to which administrators will have access. Once an administrator connects to that particular cloud server, he will be able to start a regular \acs{SSH} session with the remote measurement device by specifying the port of the previously opened tunnel in his connection request (\textit{reverse \acs{SSH} tunneling}).

Obviously, a measurement device will have to ensure that its tunnel remains active over the course of the study. On the other hand, each measurement device needs to connect to the cloud server using a different port number. Such automatic retry and port negotiation functionality is commonly found in open-source solutions~\footnote{\url{https://github.com/fatedier/frp}}.

\textbf{Realizes:} \ref{itm:fr-connect-to-device}


\subsection{Monitoring}
\label{sec:monitoring}

Although the solutions presented in the previous sections will enable administrators to upgrade and service individual measurement devices, no method has been laid out by which potential defects can be recognized proactively. This is important as participants will likely not monitor their devices for failure, hereby incurring a chance of missed measurements. This section concludes the system's design by outlining two more solutions that address these concerns.


\subsubsection{Meter Incidents}
\label{sec:meter-incidents}

It is clear that the system's effectiveness depends on the cyber-physical interaction with a meter such as the one described in \autoref{sec:meter-interaction}. Yet, because this interaction happens on the basis of an optical interface, it cannot be guaranteed that the communication will be stable at all times. For instance, small alterations in the alignment of transmitters and receivers may cause interruptions. Furthermore, the physical connection of the measurement probe to the measurement device may become faulty or unresponsive. Lastly, recalling the fact that the timing details to navigate a meter's menu vary from model to model and sometimes, even for the same model, it might not be possible to enable the detailed data readout of a meter. In all of these cases, administrators shall be made aware of the situation, so that they can proactively connect to a particular measurement device and attempt to resolve the issue (\textit{incident})~\footnote{Given the geographic distance of a household, participants may also be asked to re-align the measurement probe or unplug the measurement device from its power source.}. For this reason, \autoref{tab:data-api-endpoints-incidents} lists three additional endpoints of the \ref{itm:data-api} that will be used by the \ref{itm:data-aggregator} to track these incidents on a per-meter basis. To distinguish between the different types of incidents, \autoref{tab:meter-incident-type-constant} introduces another constant.

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|c|c|X|}
		\hline
		\textbf{\#} & \textbf{Method} & \textbf{Path} \\
	    \hline
	    \labeltext[Endpoint~11]{11}{itm:data-endpoint-11} & \texttt{GET} & \texttt{/household/meter/:uuid/incident} \\
	   	\labeltext[Endpoint~12]{12}{itm:data-endpoint-12} & \texttt{POST} & \texttt{/household/meter/:uuid/incident/report} \\
	    \labeltext[Endpoint~13]{13}{itm:data-endpoint-13} & \texttt{POST} & \texttt{/household/meter/:uuid/incident/resolve} \\
	    	\hline
	\end{tabularx}
  	\caption{\ref*{itm:data-api} endpoints to track meter incidents}
  	\label{tab:data-api-endpoints-incidents}
\end{table}

\FloatBarrier

\begin{table}[hbt]
	\centering
  	\begin{tabularx}{\textwidth}{|l|X|}
		\hline
		\textbf{Constant} & \textbf{Values} \\
	    \hline
	    \texttt{MeterIncidentType} & \texttt{SERIAL-PORT-UNAVAILABLE} \newline \texttt{OBIS-CODES-UNAVAILABLE} \\
	    	\hline
	\end{tabularx}
  	\caption{Meter incident constants}
  	\label{tab:meter-incident-type-constant}
\end{table}

\FloatBarrier

The control flow of this monitoring measure is rather simple. Upon initialization, the \ref{itm:data-aggregator} will fetch the list of incidents previously reported for each of the meters connected to the device. If that specific type of incident has already been reported or resolved, respectively, the \ref{itm:data-api} will take no action. If, however, a previously resolved incident is reported again, the case will be re-opened. This effectively means that there will be no history of incidents, although that can be easily changed by simply appending to the list of incidents instead of modifying existing instances.

\newpage

\autoref{fig:data-api-erm-meter-incident} showcases how incidents will be modeled on sides of the \ref{itm:data-api}.

\begin{figure}[hbt]
  \centering
  \includegraphics[width=0.9\textwidth]{resources/04_architecture/data-api-erm-7}
  \caption{Modeling of a meter's incidents}
  \label{fig:data-api-erm-meter-incident}
\end{figure}

\FloatBarrier


\subsubsection{Error Logging}
\label{sec:error-logging}

As a best practice in any application, this project will leverage a third-party error tracking software that remotely collects errors~\footnote{\url{https://rollbar.com}}, including their stack traces, so that production code can be continuously monitored and improved. This solution will be integrated into each of the system's custom built components, regardless of whether they run on the edge or cloud. To name a few practical benefits, such error tracking platforms will allow developers and administrators to:

\begin{itemize}
  \item receive alerts on new errors in real-time
  \item automatically group similar errors
  \item correlate errors with a component's version and other user metadata
\end{itemize}
